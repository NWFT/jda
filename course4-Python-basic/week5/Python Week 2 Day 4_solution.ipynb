{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d89ae2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>An example of HTML page</title>\n"
     ]
    }
   ],
   "source": [
    "#1.\tWrite a Python program to find the title tags from a given html document.\n",
    "from bs4 import BeautifulSoup\n",
    "html_doc = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "<meta http-equiv=\"Content-Type\" content=\"text/html;\n",
    "charset=iso-8859-1\">\n",
    "<title>An example of HTML page</title>\n",
    "</head>\n",
    "<body>\n",
    "<h2>This is an example HTML page</h2>\n",
    "<p>\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc at nisi velit,\n",
    "aliquet iaculis est. Curabitur porttitor nisi vel lacus euismod egestas. In hac\n",
    "habitasse platea dictumst. In sagittis magna eu odio interdum mollis. Phasellus\n",
    "sagittis pulvinar facilisis. Donec vel odio volutpat tortor volutpat commodo.\n",
    "Donec vehicula vulputate sem, vel iaculis urna molestie eget. Sed pellentesque\n",
    "adipiscing tortor, at condimentum elit elementum sed. Mauris dignissim\n",
    "elementum nunc, non elementum felis condimentum eu. In in turpis quis erat\n",
    "imperdiet vulputate. Pellentesque mauris turpis, dignissim sed iaculis eu,\n",
    "euismod eget ipsum. Vivamus mollis adipiscing viverra. Morbi at sem eget nisl\n",
    "euismod porta.</p>\n",
    "<p><a href=\"https://www.w3resource.com/html/HTML-tutorials.php\">Learn HTML from\n",
    "w3resource.com</a></p>\n",
    "<p><a href=\"https://www.w3resource.com/css/CSS-tutorials.php\">Learn CSS from \n",
    "w3resource.com</a></p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(soup.title)\n",
    "# soup.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d2d024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of paragraph tags:\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#2.\tWrite a Python program to get the number of paragraph tags of a given html document.\n",
    "print(\"Number of paragraph tags:\")\n",
    "print(len(soup.find_all(\"p\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eb17fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text in the first paragraph tag:\n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc at nisi velit,\n",
      "aliquet iaculis est. Curabitur porttitor nisi vel lacus euismod egestas. In hac\n",
      "habitasse platea dictumst. In sagittis magna eu odio interdum mollis. Phasellus\n",
      "sagittis pulvinar facilisis. Donec vel odio volutpat tortor volutpat commodo.\n",
      "Donec vehicula vulputate sem, vel iaculis urna molestie eget. Sed pellentesque\n",
      "adipiscing tortor, at condimentum elit elementum sed. Mauris dignissim\n",
      "elementum nunc, non elementum felis condimentum eu. In in turpis quis erat\n",
      "imperdiet vulputate. Pellentesque mauris turpis, dignissim sed iaculis eu,\n",
      "euismod eget ipsum. Vivamus mollis adipiscing viverra. Morbi at sem eget nisl\n",
      "euismod porta.\n"
     ]
    }
   ],
   "source": [
    "#3.\tWrite a Python program to extract the text in the first paragraph tag of a given html document.\n",
    "print(\"The text in the first paragraph tag:\")\n",
    "print(soup.find_all('p')[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9147fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.\tWrite a Python program to extract all the URLs from the webpage python.org that are nested within <li> tags from\n",
    "import requests\n",
    "url = 'https://www.python.org/'\n",
    "reqs = requests.get(url)\n",
    "soup = BeautifulSoup(reqs.text, 'lxml')\n",
    "\n",
    "urls = []\n",
    "for h in soup.find_all('li'):\n",
    "    a = h.find('a')\n",
    "    urls.append(a.attrs['href'])\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "740f33ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rz/6rwl1std7dz1npfq_pm66bfr0000gn/T/ipykernel_83372/3011374661.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#5.     Write a Python program to extract all the text from a given web page.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://en.wikipedia.org/wiki/Wiki'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mreqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Text from the said page:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "#5.\tWrite a Python program to extract all the text from a given web page.\n",
    "url = 'https://en.wikipedia.org/wiki/Wiki'\n",
    "reqs = requests.get(url)\n",
    "soup = BeautifulSoup(reqs.text, 'lxml')\n",
    "print(\"Text from the said page:\")\n",
    "print(soup.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31cb2b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "<title>Wiki - Wikipedia</title>\n",
      "title text\n",
      "Wiki - Wikipedia\n",
      "Parent content of the title:\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<title>Wiki - Wikipedia</title>\n",
      "<script>document.documentElement.className=\"client-js vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-language-alert-in-sidebar-enabled vector-feature-sticky-header-disabled vector-feature-page-tools-disabled vector-feature-page-tools-pinned-disabled vector-feature-main-menu-pinned-disabled vector-feature-limited-width-enabled vector-feature-limited-width-content-enabled\";(function(){var cookie=document.cookie.match(/(?:^|; )enwikimwclientprefs=([^;]+)/);if(cookie){var featureName=cookie[1];document.documentElement.className=document.documentElement.className.replace(featureName+'-enabled',featureName+'-disabled');}}());RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"d3435a74-02c8-4f09-ab9a-837a13031e3c\",\n",
      "\"wgCSPNonce\":false,\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Wiki\",\"wgTitle\":\"Wiki\",\"wgCurRevisionId\":1142053749,\"wgRevisionId\":1142053749,\"wgArticleId\":32851,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Webarchive template wayback links\",\"CS1 maint: archived copy as title\",\"CS1 errors: missing periodical\",\"Pages containing links to subscription-only content\",\"CS1: long volume value\",\"Articles with short description\",\"Short description matches Wikidata\",\"Wikipedia indefinitely semi-protected pages\",\"Wikipedia indefinitely move-protected pages\",\"Use mdy dates from July 2019\",\"Articles with hAudio microformats\",\"Pages including recorded pronunciations\",\"Articles containing potentially dated statements from February 2020\",\"All articles containing potentially dated statements\",\"Articles needing additional references from March 2017\",\n",
      "\"All articles needing additional references\",\"Wikipedia articles needing page number citations from October 2022\",\"All articles needing examples\",\"Articles needing examples from August 2018\",\"All articles with unsourced statements\",\"Articles with unsourced statements from July 2013\",\"Articles with unsourced statements from April 2020\",\"All articles lacking reliable references\",\"Articles lacking reliable references from July 2013\",\"Wikipedia articles in need of updating from July 2013\",\"All Wikipedia articles in need of updating\",\"Pages using Sister project links with wikidata namespace mismatch\",\"Pages using Sister project links with hidden wikidata\",\"Pages using Sister project links with default search\",\"Spoken articles\",\"Articles with Curlie links\",\"Articles with BNF identifiers\",\"Articles with GND identifiers\",\"Articles with J9U identifiers\",\"Articles with LCCN identifiers\",\"Articles with NKC identifiers\",\"Articles with FAST identifiers\",\"Articles containing video clips\",\"Wikis\",\n",
      "\"Hawaiian words and phrases\",\"Hypertext\",\"Self-organization\",\"Social information processing\"],\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\":\"wikitext\",\"wgRelevantPageName\":\"Wiki\",\"wgRelevantArticleId\":32851,\"wgIsProbablyEditable\":false,\"wgRelevantPageIsProbablyEditable\":false,\"wgRestrictionEdit\":[\"autoconfirmed\"],\"wgRestrictionMove\":[\"sysop\"],\"wgFlaggedRevsParams\":{\"tags\":{\"status\":{\"levels\":1}}},\"wgVisualEditor\":{\"pageLanguageCode\":\"en\",\"pageLanguageDir\":\"ltr\",\"pageVariantFallbacks\":\"en\"},\"wgMFDisplayWikibaseDescriptions\":{\"search\":true,\"watchlist\":true,\"tagline\":false,\"nearby\":true},\"wgWMESchemaEditAttemptStepOversample\":false,\"wgWMEPageLength\":60000,\"wgNoticeProject\":\"wikipedia\",\"wgVector2022PreviewPages\":[],\"wgMediaViewerOnClick\":true,\"wgMediaViewerEnabledByDefault\":true,\"wgPopupsFlags\":10,\"wgULSCurrentAutonym\":\"English\",\"wgEditSubmitButtonLabelPublish\":true,\"wgCentralAuthMobileDomain\":false,\"wgULSPosition\":\"interlanguage\",\"wgULSisCompactLinksEnabled\":true,\n",
      "\"wgULSisLanguageSelectorEmpty\":false,\"wgWikibaseItemId\":\"Q171\",\"GEHomepageSuggestedEditsEnableTopics\":true,\"wgGETopicsMatchModeEnabled\":false,\"wgGEStructuredTaskRejectionReasonTextInputEnabled\":false};RLSTATE={\"skins.vector.user.styles\":\"ready\",\"ext.globalCssJs.user.styles\":\"ready\",\"site.styles\":\"ready\",\"user.styles\":\"ready\",\"skins.vector.user\":\"ready\",\"ext.globalCssJs.user\":\"ready\",\"user\":\"ready\",\"user.options\":\"loading\",\"ext.cite.styles\":\"ready\",\"ext.pygments\":\"ready\",\"ext.tmh.player.styles\":\"ready\",\"mediawiki.ui.button\":\"ready\",\"skins.vector.styles\":\"ready\",\"skins.vector.icons\":\"ready\",\"mediawiki.ui.icon\":\"ready\",\"jquery.makeCollapsible.styles\":\"ready\",\"ext.visualEditor.desktopArticleTarget.noscript\":\"ready\",\"ext.wikimediaBadges\":\"ready\",\"ext.uls.interlanguage\":\"ready\",\"wikibase.client.init\":\"ready\"};RLPAGEMODULES=[\"ext.cite.ux-enhancements\",\"ext.tmh.player\",\"ext.scribunto.logs\",\"site\",\"mediawiki.page.ready\",\"jquery.makeCollapsible\",\"mediawiki.toc\",\"skins.vector.js\",\n",
      "\"skins.vector.es6\",\"mmv.head\",\"mmv.bootstrap.autostart\",\"ext.visualEditor.desktopArticleTarget.init\",\"ext.visualEditor.targetLoader\",\"ext.eventLogging\",\"ext.wikimediaEvents\",\"ext.navigationTiming\",\"ext.cx.eventlogging.campaigns\",\"ext.centralNotice.geoIP\",\"ext.centralNotice.startUp\",\"ext.gadget.ReferenceTooltips\",\"ext.gadget.charinsert\",\"ext.gadget.extra-toolbar-buttons\",\"ext.gadget.switcher\",\"ext.centralauth.centralautologin\",\"ext.popups\",\"ext.echo.centralauth\",\"ext.uls.compactlinks\",\"ext.uls.interface\",\"ext.cx.uls.quick.actions\",\"wikibase.client.vector-2022\",\"ext.growthExperiments.SuggestedEditSession\"];</script>\n",
      "<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement(\"user.options@12s5i\",function($,jQuery,require,module){mw.user.tokens.set({\"patrolToken\":\"+\\\\\",\"watchToken\":\"+\\\\\",\"csrfToken\":\"+\\\\\"});});});</script>\n",
      "<link href=\"/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.pygments%2CwikimediaBadges%7Cext.tmh.player.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cjquery.makeCollapsible.styles%7Cmediawiki.ui.button%2Cicon%7Cskins.vector.icons%2Cstyles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector-2022\" rel=\"stylesheet\"/>\n",
      "<script async=\"\" src=\"/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector-2022\"></script>\n",
      "<meta content=\"\" name=\"ResourceLoaderDynamicStyles\"/>\n",
      "<link href=\"/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector-2022\" rel=\"stylesheet\"/>\n",
      "<meta content=\"MediaWiki 1.40.0-wmf.24\" name=\"generator\"/>\n",
      "<meta content=\"origin\" name=\"referrer\"/>\n",
      "<meta content=\"origin-when-crossorigin\" name=\"referrer\"/>\n",
      "<meta content=\"origin-when-cross-origin\" name=\"referrer\"/>\n",
      "<meta content=\"max-image-preview:standard\" name=\"robots\"/>\n",
      "<meta content=\"telephone=no\" name=\"format-detection\"/>\n",
      "<meta content=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f0/Wikitext-wiki_markup-wikipedia.png/1200px-Wikitext-wiki_markup-wikipedia.png\" property=\"og:image\"/>\n",
      "<meta content=\"1200\" property=\"og:image:width\"/>\n",
      "<meta content=\"779\" property=\"og:image:height\"/>\n",
      "<meta content=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f0/Wikitext-wiki_markup-wikipedia.png/800px-Wikitext-wiki_markup-wikipedia.png\" property=\"og:image\"/>\n",
      "<meta content=\"800\" property=\"og:image:width\"/>\n",
      "<meta content=\"519\" property=\"og:image:height\"/>\n",
      "<meta content=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f0/Wikitext-wiki_markup-wikipedia.png/640px-Wikitext-wiki_markup-wikipedia.png\" property=\"og:image\"/>\n",
      "<meta content=\"640\" property=\"og:image:width\"/>\n",
      "<meta content=\"416\" property=\"og:image:height\"/>\n",
      "<meta content=\"width=1000\" name=\"viewport\"/>\n",
      "<meta content=\"Wiki - Wikipedia\" property=\"og:title\"/>\n",
      "<meta content=\"website\" property=\"og:type\"/>\n",
      "<link href=\"//upload.wikimedia.org\" rel=\"preconnect\"/>\n",
      "<link href=\"//en.m.wikipedia.org/wiki/Wiki\" media=\"only screen and (max-width: 720px)\" rel=\"alternate\"/>\n",
      "<link href=\"/static/apple-touch/wikipedia.png\" rel=\"apple-touch-icon\"/>\n",
      "<link href=\"/static/favicon/wikipedia.ico\" rel=\"icon\"/>\n",
      "<link href=\"/w/opensearch_desc.php\" rel=\"search\" title=\"Wikipedia (en)\" type=\"application/opensearchdescription+xml\"/>\n",
      "<link href=\"//en.wikipedia.org/w/api.php?action=rsd\" rel=\"EditURI\" type=\"application/rsd+xml\"/>\n",
      "<link href=\"https://creativecommons.org/licenses/by-sa/3.0/\" rel=\"license\"/>\n",
      "<link href=\"https://en.wikipedia.org/wiki/Wiki\" rel=\"canonical\"/>\n",
      "<link href=\"//meta.wikimedia.org\" rel=\"dns-prefetch\"/>\n",
      "<link href=\"//login.wikimedia.org\" rel=\"dns-prefetch\"/>\n",
      "</head>\n"
     ]
    }
   ],
   "source": [
    "#6.\tWrite a Python program to retrieve the HTML code of the title, its text, and the HTML code of its parent.\n",
    "reqs = requests.get(url)\n",
    "soup = BeautifulSoup(reqs.text, 'lxml')\n",
    "print(\"title\")\n",
    "print(soup.title)\n",
    "print(\"title text\")\n",
    "print(soup.title.text)\n",
    "print(\"Parent content of the title:\")\n",
    "print(soup.title.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d24dbc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original string:\n",
      "<p>Some<b>bad<i>HTML Code</i></b></p>\n",
      "\n",
      "Formatted Unicode string:\n",
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<p>\n",
      " Some\n",
      " <b>\n",
      "  bad\n",
      "  <i>\n",
      "   HTML Code\n",
      "  </i>\n",
      " </b>\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "#7.\tWrite a Python program to create a Beautiful Soup parse tree into a nicely formatted Unicode string, with a separate line for each HTML/XML tag and string.\n",
    "\n",
    "str1 = \"<p>Some<b>bad<i>HTML Code</i></b></p>\"\n",
    "print(\"Original string:\")\n",
    "print(str1)\n",
    "soup = BeautifulSoup(str1, \"xml\")\n",
    "print(\"\\nFormatted Unicode string:\")\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6dc1694",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BeautifulSoup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rz/6rwl1std7dz1npfq_pm66bfr0000gn/T/ipykernel_83372/4031671943.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhtml_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'<a href=\"https://w3resource.com/\">Python exercises<i>w3resource</i></a>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original Markup:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BeautifulSoup' is not defined"
     ]
    }
   ],
   "source": [
    "#8.\tWrite a Python program to remove the contents of a tag in a given html document.\n",
    "\n",
    "html_content = '<a href=\"https://w3resource.com/\">Python exercises<i>w3resource</i></a>'\n",
    "soup = BeautifulSoup(html_content, \"lxml\")\n",
    "print(\"Original Markup:\")\n",
    "print(soup.a)\n",
    "tag = soup.a\n",
    "tag = tag.clear()\n",
    "print(\"\\nAfter clearing the contents in the tag:\")\n",
    "print(soup.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fab6719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Markup:\n",
      "<i>Python exercises.</i>\n",
      "\n",
      "New Markup:\n",
      "<div><p><i>Python exercises.</i></p></div>\n"
     ]
    }
   ],
   "source": [
    "#9.\tWrite a Python program to wrap an element in the specified tag and create the new wrapper.\n",
    "soup = BeautifulSoup(\"<p>Python exercises.</p>\", \"lxml\")\n",
    "print(\"Original Markup:\")\n",
    "print(soup.p.string.wrap(soup.new_tag(\"i\")))\n",
    "print(\"\\nNew Markup:\")\n",
    "print(soup.p.wrap(soup.new_tag(\"div\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81c253a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Markup:\n",
      "<a href=\"https://w3resource.com/\">Python exercises<i>w3resource</i></a>\n",
      "After decomposing:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#10.\tWrite a Python program to remove a tag from a given tree of html document and destroy it and its contents.\n",
    "html_content = '<a href=\"https://w3resource.com/\">Python exercises<i>w3resource</i></a>'\n",
    "soup = BeautifulSoup(html_content, \"lxml\")\n",
    "print(\"Original Markup:\")\n",
    "a_tag = soup.a\n",
    "print(a_tag)\n",
    "new_tag = soup.a.decompose()\n",
    "print(\"After decomposing:\")\n",
    "print(new_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07fc6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
